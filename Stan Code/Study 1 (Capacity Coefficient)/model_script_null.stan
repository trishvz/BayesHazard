// Use of this code or of its modifications is permitted by anyone provided the
// following reference is included in any publication that results:
//    Joseph W. Houpt, Steven N. MacEachern, Mario Peruggia, James T. Townsend, and
//    Trisha Van Zandt (2015).  Semiparametric Bayesian Approaches to Systems Factorial
//    Technology.  Manuscript submitted to the Journal of Mathematical Psychology.
//
//
// Stan code to fit a piecewise exponential model to data from multiple
// subjects performing in multiple conditions.  There are 6 sections of
// code.
// Section                Purpose
// --------------------------------------------------------------------------------------
// functions              Defines the piecewise exponential likelihood pieceexp_log
//                        (pdf) and its cumulative distribution function pieceexp_cdf
//                        (the cdf is not used but may be useful for generating
//                        quantities (e.g., SIC) within Stan).
// data                   Reads in data as generated by R (generate_data.r)
// transformed data       Computes data-dependent quantities needed by pieceexp_log:
//                        lags and common_lags.
// parameters             Defines the model parameters, some of which will be transformed.
// transformed parameters Transforms parameters into those actually used for sampling,
//                        computes the AR(1) log h quantities and shifts N(0,1) parameters
//                        to the appropriate normal priors.
// model                  Performs the sampling
//
functions {
	real pieceexp_log(real t,vector h,vector s, vector lags) {
		// This defines the pdf of the piecewise exponential model.
		// Argument          Definition
		// -------------------------------------------------
		// t (real)          Response time
		// s (vector)        Bin boundaries
		// h (vector)        Hazard rates
		// lags (vector)     Bin widths (s[j] - s[j-1])

                // Local variable declarations
                int i;        // loop index
		real density; // log pdf, value returned by the function
                real hh;      // temporary variable for terms in exponent (see Eqn. 5)

                // Initialize index and set hh=0
                i <- 1;
                hh <- 0;

                // Locate the bin (i) in which t is located and compute the pdf
                while (s[i+1] < t) {
                   hh <- hh + h[i] * lags[i];    
                   i <- i + 1;
                  }

                // Compute the exponent of Eqn. 5
		hh <- hh + h[i] * (t-s[i]);

		// Multiply by h[i] (add on log scale)
		density <- log(h[i]) - hh;
		return (density);
	}
	real pieceexp_cdf(real t,vector h,vector s, vector lags) {
		// This defines the pdf of the piecewise exponential model.
		// Argument          Definition
		// -------------------------------------------------
		// t (real)          Response time
		// s (vector)        Bin boundaries
		// h (vector)        Hazard rates
		// lags (vector)     Bin widths (s[j] - s[j-1])

                // Local variable declarations
                int i;        // loop index
		real cdf;     // pdf, value returned by the function
                real hh;      // temporary variable for terms in exponent (see eqn. Section 4.3)

                // Initialize index and set hh=0
                i <- 1;
                hh <- 0;

                // Locate the bin (i) in which t is located and compute the cdf
                while (s[i+1] < t) {
                  hh <- hh + h[i] * lags[i];    
                  i <- i + 1;
                  } 

                // Compute the exponent of equation in Section 4.3
		hh <- hh + h[i] * (t-s[i]);

		// Compute cumulative probability
		cdf <-  1-exp(- hh);
		return (cdf);
	}
}
data {
        // Variables passed to Stan from R
	int<lower=1> N;        // Sample size
        int<lower=1> levels;   // Number of conditions
        int<lower=1> Nsub;     // Number of subjects
        int<lower=1> J;        // number of rt bins
        int<lower=1> X[N];     // Condition identifier
        int<lower=1> isub[N];  // Subject identifier
        vector[N] t;           // The vector of response times
        vector<lower=0>[J+1] s[levels,Nsub];        // Bin boundaries (quantiles)
        vector<lower=0>[J+1] common_s[levels,Nsub]; // Common bin boundaries (for null model)
}
transformed data {
        // Computation of lags and common_lags used by functions
        vector<lower=0>[J] lags[levels,Nsub];        // Bin widths
        vector<lower=0>[J] common_lags[levels,Nsub]; // Common bin widths (for null model)

        // Dimensionality variable for the reduced null model
        int<lower=1> levels1;

        // The third level is now constrained, so the dimensionality of h will be reduced
	// to levels - 1
        levels1 <- levels-1;
	
        // For each subject and condition, compute the bin widths as s[j] - s[j-1]
        for(i in 1:Nsub) {       // i is subject
           for(l in 1:levels) {  // l is level (condition)
	   
	    // The first bin width is equal to s[2]; s[1] = 0
            lags[l,i,1] <- s[l,i,2];
            common_lags[l,i,1] <- common_s[l,i,2];

            // The rest of the bin widths are obtain by lags of s
            for (j in 2:J) {
                lags[l,i,j] <- s[l,i,j+1] - s[l,i,j];
                common_lags[l,i,j] <- common_s[l,i,j+1] - common_s[l,i,j];
                }
             }
        }     
}
parameters {
            // Define the untransformed parameter values.  See Figure 2.

        // mu_mu hyperparameters
        real mu_0;              // Mean of mu_mu
        real<lower=0> var_mu_0; // Variance of mu_mu

        // mu_alpha hyperparameters
        real alpha_0;                // Mean of mu_alpha
        real<lower=0> var_alpha_0;   // Variance of mu_alpha

        // To stabilize the sampler, all parameters with normal priors were drawn first
	// from N(0,1) priors (_raw) and then transformed to N(mu,sigma)
        real mu_mu_raw[Nsub];        // Untransformed mean of mu_ic (mu_mu)
        real<lower=0> var_mu[Nsub];  // Variance of mu_ic (not in the hierarchy)
	
        real mu_alpha_raw[Nsub];        // Untransformed mean of alpha_ic
        real<lower=0> var_alpha[Nsub];  // Variance of alpha_ic (not in the hierarchy)

        vector[levels] mu_raw[Nsub];    // Untransformed mu_ic
        vector[levels] alpha_raw[Nsub]; // Untransformed alpha_ic
	
        vector<lower=0>[levels1] var_h[Nsub]; // Variance of epsilon_icj (not in the hierarchy)

        vector[J] ln_h_raw[Nsub,levels1];     // Untransformed log hazard rates

}
transformed parameters {
            // Define the transformed parameter values.  See Figure 2.
            // *Note the dimensionality reduction for all parameters directly involving h.
	    
        vector<lower=0>[J] h[Nsub,levels];           // Hazard rates
        vector<lower=-1,upper=1>[levels1] phi[Nsub]; // *Autoregressive coefficient
        vector<lower=0>[levels1] sigma_h[Nsub];      // *Standard deviations of epsilon_icj
        real<lower=0> sigma_mu[Nsub];                // Standard deviations of mu_ic	
        real<lower=0> sigma_alpha[Nsub];             // Standard deviations of alpha_ic	
        real<lower=0> sigma_mu_0;                    // Standard deviation of mu_mu
        real<lower=0> sigma_alpha_0;                 // Standard deviation of mu_alpha
	
        real mu_mu[Nsub];                            // Mean of mu_ic
        real mu_alpha[Nsub];                         // Mean of alpha_ic
        vector[levels1] mu[Nsub];                    // *Values of mu_ic
        vector[levels1] alpha[Nsub];                 // *Values of alpha_ic
        vector[J] ln_h[Nsub,levels1];                // *Values of log hazard rates

        // Compute the standard deviation hyperparameters by square roots of the variance
        sigma_mu_0 <- sqrt(var_mu_0);
        sigma_alpha_0 <- sqrt(var_alpha_0);

        // For each subject i:
        for(i in 1:Nsub) {
	    // Transform parameters with N(0,1) priors to their appropriate N(mu,sigma) priors
	    mu_mu[i] <- sigma_mu_0*mu_mu_raw[i] + mu_0;
	    mu_alpha[i] <- mu_alpha_raw[i]*sigma_alpha_0 + alpha_0; // alpha[i,l]

            // Transform variance parameters to standard deviations by square roots of the variance
            sigma_mu[i] <- sqrt(var_mu[i]);
            sigma_alpha[i] <- sqrt(var_alpha[i]);

            // For each level l (reduced for null constraint):
            for(l in 1:levels1) {
	        // Transform parameters with N(0,1) priors to their appropriate N(mu,sigma) priors
		mu[i,l] <- mu_mu[i] + mu_raw[i,l]*sigma_mu[i];
		alpha[i,l] <- mu_alpha[i] + alpha_raw[i,l]*sigma_alpha[i];

                // Compute the autocorrelation coefficient as an inverse logit of alpha
                phi[i,l] <- 2./(1. + exp(-alpha[i,l])) - 1.;

                // Transform the innovation variance to standard deviation
                sigma_h[i,l] <- sqrt(var_h[i,l]);

                // Transform the N(O,1) ln_h_raw to the appropriate N(mu,sigma) priors
		ln_h[i,l,1] <- mu[i,l] + ln_h_raw[i,l,1]*sigma_h[i,l]/sqrt(1.-phi[i,l]*phi[i,l]);	
                for (j in 2:J) {
                    ln_h[i,l,j] <- mu[i,l] + phi[i,l]*(ln_h[i,l,j-1]-mu[i,l]) + ln_h_raw[i,l,j]*sigma_h[i,l];
		    }
                // Compute the hazard rates    
                h[i,l] <- exp(ln_h[i,l]);
            }
	    // Constrain the hazard rates in the third condition to be equal to the sum of the rates in
	    // the first and second conditions
	    h[i,3] <- h[i,1] + h[i,2];
        }
}
model {
       // Sample from the piecewise exponential model across subjects and conditions
        int K; // Index for subject
        int M; // Index for condition

	// Define the hyperpriors for mu_mu
        var_mu_0 ~ gamma(1.,1.); 
        mu_0 ~ normal(0,1);

        // Define the hyperpriors for mu_alpha
        alpha_0 ~ normal(0,1); // mu_alpha[i]
        var_alpha_0 ~ gamma(1.,1.);

        // For each subject i
        for (i in 1:Nsub) {
	    // Define the priors for the untransformed parameters
            mu_mu_raw[i] ~ normal(0,1);  // Mean and variance for mu_ic
            var_mu[i] ~ gamma(1,1);

            mu_alpha_raw[i] ~ normal(0,1); // Mean and variance for alpha_ic
            var_alpha[i] ~ gamma(1,1);
     
            // For each level l (dimensionality reduced)
            for (l in 1:levels1) {
	    
	        // Define the priors for the untransformed parameters mu_raw and alpha_raw
                mu_raw[i,l] ~ normal(0,1);
                alpha_raw[i,l] ~ normal(0,1);

                // Define the prior for the innovation variance
                var_h[i,l] ~ gamma(1,1);

                // Define the priors for the untransformed log hazard rates
                ln_h_raw[i,l,1] ~ normal(0,1);
                for (j in 2:J) {
		    ln_h_raw[i,l,j] ~ normal(0,1);
                    }
                }
             }
	// Sample from the posterior over all subjects and levels by way of the one-dimensional
	// vectors isub, X and t.
	// For each observation n in the vector t of RTs,
	for (n in 1:N) {
                K <- isub[n];  // determine the subject who contributed the RT,
                M <- X[n];     // determine the condition under which the RT was observed, and
		t[n] ~ pieceexp(h[K,M],common_s[M,K],common_lags[M,K]); // compute the likelihood of t[n].
		// Note the use of common bin boundaries; the sum of hazard rates across different
		// boundaries makes no sense.
		}
}

